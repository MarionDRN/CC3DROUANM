---
title: "CC3Marion"
author: "Marion Drouan"
date: "2023-01-02"
output: github_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=TRUE)
```

```{r library, include=FALSE}
library(knitr)
library(phyloseq)
library(dada2)
library(DECIPHER)
library(phangorn)
library(ggplot2)
library(gridExtra)
library(shiny)
library(miniUI)
library(caret)
library(pls)
library(e1071)
library(ggplot2)
library(randomForest)
library(dplyr)
library(ggrepel)
#library(nlme)
library(devtools)
library(reshape2)
library(PMA)
#library(structSSI)
library(ade4)
library(ggnetwork)
library(intergraph)
library(scales)
library(genefilter)
library(impute)
library(phyloseqGraphTest)
library(Biostrings)
```

```{bash, eval=FALSE}
mkdir data
wget -P data -i URL
```

```{r}
path <- "data"
list.files(path)
```

```{r}
fnR1 <- sort(list.files(path, pattern="_1", full.names = TRUE))
fnR2 <- sort(list.files(path, pattern="_2", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnR1), "_"), `[`, 1)
```

```{r}
plotQualityProfile(fnR1[1:2])
```

```{r}
plotQualityProfile(fnR2[1:2])
```

#Filter and trim

```{r}
filtR1 <- file.path(path, "filtered", paste0(sample.names, "_1_filt.fastq.gz"))
filtR2 <- file.path(path, "filtered", paste0(sample.names, "_2_filt.fastq.gz"))
names(filtR1) <- sample.names
names(filtR2) <- sample.names
```

```{r}
out <- filterAndTrim(fnR1, filtR1, fnR2, filtR2, truncLen=c(250,240), trimLeft=c(18,18), maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=TRUE)

head(out)
```

```{r}
table(file.exists(filtR1))
table(file.exists(filtR2))

exists <- file.exists(filtR1) & file.exists(filtR2)
filtR1 <- filtR1[exists]
filtR2 <- filtR2[exists]
```

#Learn the Error Rates

```{r}
errR1 <- learnErrors(filtR1, multithread=TRUE)

errR2 <- learnErrors(filtR2, multithread=TRUE)
```

```{r}
plotErrors(errR1, nominalQ=TRUE)
```

```{r}
plotErrors(errR2, nominalQ=TRUE)
```

#Sample Inference

```{r}
dadaR1 <- dada(filtR1, err=errR1, multithread=TRUE)
```

```{r}
dadaR2 <- dada(filtR2, err=errR2, multithread=TRUE)
```

```{r}
dadaR1[[1]]
```

```{r}
dadaR2[[1]]
```

#Merge paired reads

```{r}
mergers <- mergePairs(dadaR1, filtR1, dadaR2, filtR2, verbose=TRUE)
head(mergers[[1]])
```

#Construct sequence table

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
table(nchar(getSequences(seqtab)))
```

#Remove chimeras

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```

```{r}
sum(seqtab.nochim)/sum(seqtab)
```

#Track reads through the pipeline

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaR1, getN), sapply(dadaR2, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

#Assign taxonomy

```{bash, include=TRUE, eval=FALSE}
wget https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz?download=1
```

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "silva_nr99_v138.1_train_set.fa.gz?download=1", multithread=TRUE)
```

```{r}
taxa.print <- taxa 
rownames(taxa.print) <- NULL
head(taxa.print)
```

#Handoff to phyloseq

```{r}
theme_set(theme_bw())
```

```{r}
read.csv2("dataframe .csv", header = TRUE, sep = ";", quote = "/", dec = ",", fill = TRUE, comment.char = "")
```
